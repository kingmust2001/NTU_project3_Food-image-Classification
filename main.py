# -*- coding: utf-8 -*-
"""NTU_project3_Food-image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5gvXv8gLTifSobwBuEiDoxNqJLdfHwD

## learning

* A greater batch size usually gives a more stable gradient. But the GPU memory is limited, so please adjust it carefully.

* torchvision基本上是PIL模組裡面提供的函數進行影像轉換 只是torchvision將PIL的function包裝成在torchvision的class(functional)方式進行宣告transforms.Compose將 有的處理包裝成一個fun，以方便後續的程式操作

* image resize大小? model深vs寬? normalization在totensor前or後?

* torchvision.datasets分為DatasetFolder(已將image by不同label分在不同資料夾) & ImageFolder(繼承自DatasetFolder, 所有image都放在相同資料夾, 需有額外txt檔描述label對應的image) 

* The extracted feature map must be flatten before going to fully-connected layers.  CNN => flatten => fc_layer

## import package
"""

#data processing
import numpy as np
#visualization
from PIL import Image
#DL framework
import torch
import torch.nn as nn
from torch.utils.data import ConcatDataset, Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import DatasetFolder
#other
from tqdm.auto import tqdm

"""## download data

"""

!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip

!unzip -q food-11.zip

"""## Dataset, Data Loader, and Transforms

Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.

Here, since our data are stored in folders by class labels, we can directly apply torchvision.datasets.DatasetFolder for wrapping data without much effort.

Please refer to [PyTorch official website](https://pytorch.org/vision/stable/transforms.html) for details about different transforms.
"""

train_tfm = transforms.Compose([ 
    transforms.Resize((128,128)),
    #transforms.RandomHorizontalFlip(p=0.5),
    #transforms.ColorJitter(brightness=(0, 5), contrast=(0, 5), saturation=(0, 5), hue=(-0.1, 0.1)),
    transforms.ToTensor(), #Convert a PIL Image or numpy.ndarray to tensor. This transform does not support torchscript.
    #transforms.Normalize(mean=(0.5, 0.5, 0.5),std=(0.1, 0.1, 0.1)), #將影像(torch tensor)的每個channel(R,G,B)依據平均數和標準差分別進行影像的正規化(Z-score)
])

test_tfm = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor()
])

"""
root (string) – Root directory path.
loader (callable) – A function to load a sample given its path.
extensions (tuple[string]) – A list of allowed extensions. both extensions and is_valid_file should not be passed.
transform (callable, optional) – A function/transform that takes in a sample and returns a transformed version. E.g, transforms.RandomCrop for images.
target_transform (callable, optional) – A function/transform that takes in the target and transforms it.
is_valid_file – A function that takes path of a file and check if the file is a valid file (used to check of corrupt files) both extensions and is_valid_file should not be passed.
"""

"""
num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)
pin_memory (bool, optional) – If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.
"""
batch_size = 16
train_set = DatasetFolder('food-11/training/labeled', loader = lambda x: Image.open(x), extensions='jpg', transform = train_tfm)
valid_set = DatasetFolder("food-11/validation", loader=lambda x: Image.open(x), extensions="jpg", transform=test_tfm)
unlabeled_set = DatasetFolder("food-11/training/unlabeled", loader=lambda x: Image.open(x), extensions="jpg", transform=train_tfm)
test_set = DatasetFolder("food-11/testing", loader=lambda x: Image.open(x), extensions="jpg", transform=test_tfm)

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle = True, pin_memory=True, num_workers=8)
valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)

"""## model

The basic model here is simply a stack of convolutional layers followed by some fully-connected layers.

Since there are three channels for a color image (RGB), the input channels of the network must be three.
In each convolutional layer, typically the channels of inputs grow, while the height and width shrink (or remain unchanged, according to some hyperparameters like stride and padding).

Before fed into fully-connected layers, the feature map must be flattened into a single one-dimensional vector (for each image).
These features are then transformed by the fully-connected layers, and finally, we obtain the "logits" for each class.
"""

class Classifier(nn.Module):
  def __init__(self):
    super(Classifier, self).__init__()
    # The arguments for commonly used modules:
    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
    # torch.nn.MaxPool2d(kernel_size, stride, padding)

    # input image size: [3, 128, 128]
    self.net = nn.Sequential(
        nn.Conv2d(3, 64, 3, 1, 1),
        nn.BatchNorm2d(64), #Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .
        nn.ReLU(),
        nn.MaxPool2d(2, 2, 0),

        nn.Conv2d(64, 128, 3, 1, 2),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(2, 2, 0),

        nn.Conv2d(128, 256, 3, 1, 1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(4, 4, 0),
    )
    self.fc_layer = nn.Sequential(
        nn.Linear(256*8*8, 256),
        nn.ReLU(),
        nn.Linear(256, 256),
        nn.ReLU(),
        nn.Linear(256, 11)
    )
  def forward(self, x):
    # input (x): [batch_size, 3, 128, 128]
    # output: [batch_size, 11]
    # Extract features by convolutional layers.
    x = self.net(x)
    # The extracted feature map must be flatten before going to fully-connected layers.
    x = x.flatten(1)
    # The features are transformed by fully-connected layers to obtain the final "logits".
    x = self.fc_layer(x)
    return x

"""## Training

You can finish supervised learning by simply running the provided code without any modification.

The function "get_pseudo_labels" is used for semi-supervised learning. It is expected to get better performance if you use unlabeled data for semi-supervised learning. However, you have to implement the function on your own and need to adjust several hyperparameters manually.

For more details about semi-supervised learning, please refer to Prof. Lee's slides.
"""

def get_device():
  return "cuda" if torch.cuda.is_available() else "cpu"
device = get_device()
device

def get_pseudo_labels(dataset, model, threshold=0.65):
  # This functions generates pseudo-labels of a dataset using given model.
  # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.
  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
  model.eval()
  softmax = nn.Softmax(dim=-1) #dim (int) – A dimension along which Softmax will be computed (so every slice along dim will sum to 1). dim=-1 or 針對某行算softmax
  new_dataset = []
  for batch in tqdm(data_loader):
    img, _ = batch
    # Forward the data
    # Using torch.no_grad() accelerates the forward process.
    with torch.no_grad():
      logits = model(img.to(device))
    probs = softmax(logits)
    pred, _ = torch.max(probs,1)
    new_dataset.append(probs[pred >= threshold])
  dataset = new_dataset
  model.train()
  return dataset

#dataset = get_pseudo_labels(unlabeled_set, Classifier().to(device), threshold=0.65)

#len(dataset[0])

model = Classifier().to(device)
model.device = device

config = {
    'num_epoch': 10,                # maximum number of epochs
    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)
    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)
        'lr': 0.0001,                 # learning rate of ADAM
        'weight_decay':1e-5
    },
    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)
    'model_path': './model.ckpt'  #model check point save path
}
criteria = nn.CrossEntropyLoss()
optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), **config['optim_hparas'])
# Whether to do semi-supervised learning.
do_semi = False
n_epochs = config['num_epoch']
for epoch in range(n_epochs):
  if do_semi:
    pseudo_set = get_pseudo_labels(unlabeled_set, model)
    concat_dataset = ConcatDataset(train_set, pseudo_set)
    train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
  #training
  model.train()
  train_acc = []
  train_loss = []
  for batch in tqdm(train_loader):
    x, y = batch
    x, y = x.to(device), y.to(device)
    optimizer.zero_grad()
    logits = model(x)
    batch_loss = criteria(logits, y)
    batch_loss.backward()
    # Clip the gradient norms for stable training.
    #grad_norm = nn.utils.clip_grad_norm(model.parameters(), max_norm = 10) #Clips gradient norm of an iterable of parameters.
    optimizer.step()
    # Compute the accuracy for "current batch."
    acc = (logits.argmax(-1) == y.to(device)).float().mean()
    # Record the loss and accuracy.
    train_loss.append(batch_loss.item()) #Returns the value of this tensor as a standard Python number. This only works for tensors with one element.
    train_acc.append(acc)
  # The average loss and accuracy of the training set is the average of the recorded values.
  train_loss = sum(train_loss) / len(train_loss)
  train_acc = sum(train_acc) / len(train_acc)
  print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")
  #validation
  model.eval()
  valid_acc = []
  valid_loss = []
  for batch in tqdm(valid_loader):
    with torch.no_grad():
      x, y = batch
      x, y = x.to(device), y.to(device)
      logits = model(x)
      batch_loss = criteria(logits, y)
      # Compute the accuracy for current batch.
      acc = (logits.argmax(dim=-1) == y.to(device)).float().mean()

      # Record the loss and accuracy.
      valid_loss.append(batch_loss.item())
      valid_acc.append(acc)

  # The average loss and accuracy for entire validation set is the average of the recorded values.
  valid_loss = sum(valid_loss) / len(valid_loss)
  valid_acc = sum(valid_acc) / len(valid_acc)

  # Print the information.
  print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")

"""## testing"""

model.eval()
prediction = []
with torch.no_grad():
  for batch in tqdm(test_loader):
    x, y = batch
    x = x.to(device)
    pred = model(x)
    prediction.extend(pred.argmax(dim=-1).cpu().numpy().tolist())

prediction

with open("prediction.csv", "w") as f:
  f.write("ID, class\n")
  for i, item in enumerate(prediction):
    f.write("{}, {}\n".format(i, item))
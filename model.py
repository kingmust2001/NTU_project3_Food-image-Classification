# -*- coding: utf-8 -*-
"""NTU_project3_Food-image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5gvXv8gLTifSobwBuEiDoxNqJLdfHwD


## import package
"""

#data processing
import numpy as np
#visualization
from PIL import Image
#DL framework
import torch
import torch.nn as nn
from torch.utils.data import ConcatDataset, Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import DatasetFolder
#other
from tqdm.auto import tqdm



"""## model

The basic model here is simply a stack of convolutional layers followed by some fully-connected layers.

Since there are three channels for a color image (RGB), the input channels of the network must be three.
In each convolutional layer, typically the channels of inputs grow, while the height and width shrink (or remain unchanged, according to some hyperparameters like stride and padding).

Before fed into fully-connected layers, the feature map must be flattened into a single one-dimensional vector (for each image).
These features are then transformed by the fully-connected layers, and finally, we obtain the "logits" for each class.
"""

class Classifier(nn.Module):
  def __init__(self):
    super(Classifier, self).__init__()
    # The arguments for commonly used modules:
    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
    # torch.nn.MaxPool2d(kernel_size, stride, padding)

    # input image size: [3, 128, 128]
    self.net = nn.Sequential(
        nn.Conv2d(3, 64, 3, 1, 1),
        nn.BatchNorm2d(64), #Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .
        nn.ReLU(),
        nn.MaxPool2d(2, 2, 0),

        nn.Conv2d(64, 128, 3, 1, 2),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(2, 2, 0),

        nn.Conv2d(128, 256, 3, 1, 1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(4, 4, 0),
    )
    self.fc_layer = nn.Sequential(
        nn.Linear(256*8*8, 256),
        nn.ReLU(),
        nn.Linear(256, 256),
        nn.ReLU(),
        nn.Linear(256, 11)
    )
  def forward(self, x):
    # input (x): [batch_size, 3, 128, 128]
    # output: [batch_size, 11]
    # Extract features by convolutional layers.
    x = self.net(x)
    # The extracted feature map must be flatten before going to fully-connected layers.
    x = x.flatten(1)
    # The features are transformed by fully-connected layers to obtain the final "logits".
    x = self.fc_layer(x)
    return x


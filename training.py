# -*- coding: utf-8 -*-
"""NTU_project3_Food-image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5gvXv8gLTifSobwBuEiDoxNqJLdfHwD

## import package
"""

#data processing
import numpy as np
#visualization
from PIL import Image
#DL framework
import torch
import torch.nn as nn
from torch.utils.data import ConcatDataset, Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import DatasetFolder
#other
from tqdm.auto import tqdm



"""## Training

You can finish supervised learning by simply running the provided code without any modification.

The function "get_pseudo_labels" is used for semi-supervised learning. It is expected to get better performance if you use unlabeled data for semi-supervised learning. However, you have to implement the function on your own and need to adjust several hyperparameters manually.

For more details about semi-supervised learning, please refer to Prof. Lee's slides.
"""

def get_device():
  return "cuda" if torch.cuda.is_available() else "cpu"
device = get_device()
device

def get_pseudo_labels(dataset, model, threshold=0.65):
  # This functions generates pseudo-labels of a dataset using given model.
  # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.
  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
  model.eval()
  softmax = nn.Softmax(dim=-1) #dim (int) – A dimension along which Softmax will be computed (so every slice along dim will sum to 1). dim=-1 or 針對某行算softmax
  new_dataset = []
  for batch in tqdm(data_loader):
    img, _ = batch
    # Forward the data
    # Using torch.no_grad() accelerates the forward process.
    with torch.no_grad():
      logits = model(img.to(device))
    probs = softmax(logits)
    pred, _ = torch.max(probs,1)
    new_dataset.append(probs[pred >= threshold])
  dataset = new_dataset
  model.train()
  return dataset

#dataset = get_pseudo_labels(unlabeled_set, Classifier().to(device), threshold=0.65)

#len(dataset[0])

model = Classifier().to(device)
model.device = device

config = {
    'num_epoch': 10,                # maximum number of epochs
    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)
    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)
        'lr': 0.0001,                 # learning rate of ADAM
        'weight_decay':1e-5
    },
    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)
    'model_path': './model.ckpt'  #model check point save path
}
criteria = nn.CrossEntropyLoss()
optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), **config['optim_hparas'])
# Whether to do semi-supervised learning.
do_semi = False
n_epochs = config['num_epoch']
for epoch in range(n_epochs):
  if do_semi:
    pseudo_set = get_pseudo_labels(unlabeled_set, model)
    concat_dataset = ConcatDataset(train_set, pseudo_set)
    train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
  #training
  model.train()
  train_acc = []
  train_loss = []
  for batch in tqdm(train_loader):
    x, y = batch
    x, y = x.to(device), y.to(device)
    optimizer.zero_grad()
    logits = model(x)
    batch_loss = criteria(logits, y)
    batch_loss.backward()
    # Clip the gradient norms for stable training.
    #grad_norm = nn.utils.clip_grad_norm(model.parameters(), max_norm = 10) #Clips gradient norm of an iterable of parameters.
    optimizer.step()
    # Compute the accuracy for "current batch."
    acc = (logits.argmax(-1) == y.to(device)).float().mean()
    # Record the loss and accuracy.
    train_loss.append(batch_loss.item()) #Returns the value of this tensor as a standard Python number. This only works for tensors with one element.
    train_acc.append(acc)
  # The average loss and accuracy of the training set is the average of the recorded values.
  train_loss = sum(train_loss) / len(train_loss)
  train_acc = sum(train_acc) / len(train_acc)
  print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")
  #validation
  model.eval()
  valid_acc = []
  valid_loss = []
  for batch in tqdm(valid_loader):
    with torch.no_grad():
      x, y = batch
      x, y = x.to(device), y.to(device)
      logits = model(x)
      batch_loss = criteria(logits, y)
      # Compute the accuracy for current batch.
      acc = (logits.argmax(dim=-1) == y.to(device)).float().mean()

      # Record the loss and accuracy.
      valid_loss.append(batch_loss.item())
      valid_acc.append(acc)

  # The average loss and accuracy for entire validation set is the average of the recorded values.
  valid_loss = sum(valid_loss) / len(valid_loss)
  valid_acc = sum(valid_acc) / len(valid_acc)

  # Print the information.
  print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")

"""## testing"""

model.eval()
prediction = []
with torch.no_grad():
  for batch in tqdm(test_loader):
    x, y = batch
    x = x.to(device)
    pred = model(x)
    prediction.extend(pred.argmax(dim=-1).cpu().numpy().tolist())

prediction

with open("prediction.csv", "w") as f:
  f.write("ID, class\n")
  for i, item in enumerate(prediction):
    f.write("{}, {}\n".format(i, item))
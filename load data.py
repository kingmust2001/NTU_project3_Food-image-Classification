# -*- coding: utf-8 -*-
"""NTU_project3_Food-image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5gvXv8gLTifSobwBuEiDoxNqJLdfHwD

## learning

* A greater batch size usually gives a more stable gradient. But the GPU memory is limited, so please adjust it carefully.

* torchvision基本上是PIL模組裡面提供的函數進行影像轉換 只是torchvision將PIL的function包裝成在torchvision的class(functional)方式進行宣告transforms.Compose將 有的處理包裝成一個fun，以方便後續的程式操作

* image resize大小? model深vs寬? normalization在totensor前or後?

* torchvision.datasets分為DatasetFolder(已將image by不同label分在不同資料夾) & ImageFolder(繼承自DatasetFolder, 所有image都放在相同資料夾, 需有額外txt檔描述label對應的image) 

* The extracted feature map must be flatten before going to fully-connected layers.  CNN => flatten => fc_layer

## import package
"""

#data processing
import numpy as np
#visualization
from PIL import Image
#DL framework
import torch
import torch.nn as nn
from torch.utils.data import ConcatDataset, Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import DatasetFolder
#other
from tqdm.auto import tqdm

"""## download data

"""

!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip

!unzip -q food-11.zip

"""## Dataset, Data Loader, and Transforms

Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.

Here, since our data are stored in folders by class labels, we can directly apply torchvision.datasets.DatasetFolder for wrapping data without much effort.

Please refer to [PyTorch official website](https://pytorch.org/vision/stable/transforms.html) for details about different transforms.
"""

train_tfm = transforms.Compose([ 
    transforms.Resize((128,128)),
    #transforms.RandomHorizontalFlip(p=0.5),
    #transforms.ColorJitter(brightness=(0, 5), contrast=(0, 5), saturation=(0, 5), hue=(-0.1, 0.1)),
    transforms.ToTensor(), #Convert a PIL Image or numpy.ndarray to tensor. This transform does not support torchscript.
    #transforms.Normalize(mean=(0.5, 0.5, 0.5),std=(0.1, 0.1, 0.1)), #將影像(torch tensor)的每個channel(R,G,B)依據平均數和標準差分別進行影像的正規化(Z-score)
])

test_tfm = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor()
])

"""
root (string) – Root directory path.
loader (callable) – A function to load a sample given its path.
extensions (tuple[string]) – A list of allowed extensions. both extensions and is_valid_file should not be passed.
transform (callable, optional) – A function/transform that takes in a sample and returns a transformed version. E.g, transforms.RandomCrop for images.
target_transform (callable, optional) – A function/transform that takes in the target and transforms it.
is_valid_file – A function that takes path of a file and check if the file is a valid file (used to check of corrupt files) both extensions and is_valid_file should not be passed.
"""

"""
num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)
pin_memory (bool, optional) – If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.
"""
batch_size = 16
train_set = DatasetFolder('food-11/training/labeled', loader = lambda x: Image.open(x), extensions='jpg', transform = train_tfm)
valid_set = DatasetFolder("food-11/validation", loader=lambda x: Image.open(x), extensions="jpg", transform=test_tfm)
unlabeled_set = DatasetFolder("food-11/training/unlabeled", loader=lambda x: Image.open(x), extensions="jpg", transform=train_tfm)
test_set = DatasetFolder("food-11/testing", loader=lambda x: Image.open(x), extensions="jpg", transform=test_tfm)

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle = True, pin_memory=True, num_workers=8)
valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)

